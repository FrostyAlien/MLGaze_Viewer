# MLGaze Viewer

A Rerun-based visualization tool for Magic Leap 2 eye tracking data, providing synchronized 3D gaze ray visualization and 2D camera frame analysis.

## Overview

MLGaze Viewer transforms raw Magic Leap 2 sensor data into interactive 3D visualizations, enabling researchers and developers to analyze eye tracking behavior, head movements, and sensor data in real-time. Built on a modular plugin architecture, it supports extensible analytics and custom visualizations.

## Key Features

- **3D Gaze Visualization**: Real-time rendering of eye gaze rays in 3D world space
- **Synchronized Playback**: Frame-accurate synchronization between gaze data and camera footage
- **Multi-Sensor Support**: Integrated visualization of gaze, camera, and IMU data
- **Plugin Architecture**: Extensible analytics framework for custom analysis modules
- **Interactive Configuration**: Terminal UI for visualization settings and plugin management
- **AOI Analysis**: Built-in Area of Interest tracking and analysis

## Installation

### Prerequisites

- Python 3.12 or higher
- UV package manager

### Setup

1. Clone the repository:
```bash
git clone https://github.com/FrostyAlien/MLGaze_Viewer/
cd MLGaze_Viewer
```

2. Install dependencies using UV:
```bash
uv sync
```

### Optional: Object Detection Support

To enable object detection features:
```bash
# RF-DETR models will be downloaded automatically on first use
# Requires ~500MB for base model
```

## Usage

### Basic Visualization

```bash
uv run scripts/visualize.py --input <data-directory>
```

### With Configuration UI

```bash
uv run scripts/visualize.py
```

## Data Format

The tool expects the following data structure in your input directory:

```
input/
â”œâ”€â”€ gaze_data_*.csv          # 3D gaze vectors
â”œâ”€â”€ gaze_screen_coords_*.csv # 2D screen projections
â”œâ”€â”€ camera_data_*.csv        # Camera poses
â”œâ”€â”€ imu_log_*.csv           # IMU sensor data
â””â”€â”€ frames/                 # Extracted camera frames
    â””â”€â”€ *.jpg
```

## Features

### Completed âœ…
- âœ… **Object Detection**: RF-DETR integration with configurable models (nano, small, medium, base)
- âœ… **Plugin Dependency System**: DAG-based automatic execution ordering
- âœ… **Multi-Camera Support**: Synchronized visualization across cameras
- âœ… **Comprehensive Logging**: Debug, performance, and error tracking

### In Progress ðŸš§
- ðŸš§ **Gaze-Object Interaction**: Mapping gaze to detected objects
- ðŸš§ **3D Instance Tracking**: HDBSCAN clustering for object persistence

### Planned ðŸ“‹
- [ ] **Sensor Recorder**: ML2 sensor recording application (in development)
- [ ] **Heatmap Generation**: Gaze density visualization overlays for attention analysis
- [ ] **Real-time Streaming**: Live data analysis support

## Architecture

The project uses a sophisticated plugin-based architecture with automatic dependency management:

### Plugin Dependency System
- **DAG-based Resolution**: Plugins declare dependencies, system automatically determines execution order
- **Topological Sort**: Ensures plugins run in correct sequence based on dependencies
- **Graceful Degradation**: Optional dependencies enhance functionality when available

### Core Components
- **DataLoader**: Handles organized session data with multi-camera support
- **SessionData**: Central container with plugin results storage
- **Plugin System** (`src/plugin_sys/`): Advanced dependency management and execution
- **Analytics Plugins**: Extensible modules with dependency declarations
- **RerunVisualizer**: Orchestrates sensors and plugins with automatic ordering


## Development

### Adding Custom Plugins

Create a new plugin by inheriting from `AnalyticsPlugin`:

```python
from src.plugin_sys.base import AnalyticsPlugin
from typing import List, Dict, Any

class CustomAnalyzer(AnalyticsPlugin):
    def get_dependencies(self) -> List[str]:
        return ["ObjectDetector"]  # Requires ObjectDetector to run first
    
    def get_optional_dependencies(self) -> List[str]:
        return ["AOIAnalyzer"]  # Enhanced if AOI data available
    
    def process(self, session, config: Dict[str, Any]):
        # Access dependency results
        detections = config["dependencies"]["ObjectDetector"]
        # Your analysis logic here
        return results
```

### Project Structure

```
MLGaze_Viewer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/           # Core data structures and session management
â”‚   â”œâ”€â”€ plugin_sys/     # Plugin infrastructure with DAG dependency management
â”‚   â”œâ”€â”€ sensors/        # Sensor data handlers
â”‚   â”œâ”€â”€ analytics/      # Analytics plugins (ObjectDetector, AOIAnalyzer, etc.)
â”‚   â”œâ”€â”€ visualization/  # Rerun visualization orchestrator
â”‚   â”œâ”€â”€ ui/            # Terminal UI components
â”‚   â””â”€â”€ utils/         # Utilities (logging, data loading)
â”œâ”€â”€ models/            # ML models for object detection
â”œâ”€â”€ input/             # Session data input directory
â”œâ”€â”€ plugins/           # Custom plugin modules
â””â”€â”€ scripts/          # Entry points
```
